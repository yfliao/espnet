<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.enh.layers.dcunet &mdash; ESPnet 202402 documentation</title><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202402
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.diar.html">espnet2.diar package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.s2st.html">espnet2.s2st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.s2t.html">espnet2.s2t package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../_gen/espnet2.slu.html">espnet2.slu package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">espnet2.enh.layers.dcunet</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for espnet2.enh.layers.dcunet</h1><div class="highlight"><pre>
<span></span><span class="c1"># The implementation of DCUNet in</span>
<span class="c1"># S. Welker, et al.  “Speech Enhancement with Score-Based</span>
<span class="c1"># Generative Models in the Complex STFT Domain”</span>
<span class="c1"># The implementation is based on:</span>
<span class="c1"># https://github.com/sp-uhh/sgmse</span>
<span class="c1"># Licensed under MIT</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.modules.batchnorm</span> <span class="kn">import</span> <span class="n">_BatchNorm</span>


<div class="viewcode-block" id="GaussianFourierProjection"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.GaussianFourierProjection">[docs]</a><span class="k">class</span> <span class="nc">GaussianFourierProjection</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gaussian random features for encoding time steps.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span> <span class="o">=</span> <span class="n">complex_valued</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">complex_valued</span><span class="p">:</span>
            <span class="c1"># If the output is real-valued, we concatenate sin+cos</span>
            <span class="c1">#  of the features to avoid ambiguities.</span>
            <span class="c1"># Therefore, in this case the effective embed_dim is</span>
            <span class="c1"># cut in half. For the complex-valued case,</span>
            <span class="c1"># we use complex numbers which each represent sin+cos</span>
            <span class="c1"># directly, so the ambiguity is avoided directly,</span>
            <span class="c1"># and this halving is not necessary.</span>
            <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="c1"># Randomly sample weights during initialization. These weights are fixed</span>
        <span class="c1"># during optimization and are not trainable.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<div class="viewcode-block" id="GaussianFourierProjection.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.GaussianFourierProjection.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">t_proj</span> <span class="o">=</span> <span class="n">t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">t_proj</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t_proj</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">t_proj</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="DiffusionStepEmbedding"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DiffusionStepEmbedding">[docs]</a><span class="k">class</span> <span class="nc">DiffusionStepEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Diffusion-Step embedding as in DiffWave / Vaswani et al. 2017.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span> <span class="o">=</span> <span class="n">complex_valued</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">complex_valued</span><span class="p">:</span>
            <span class="c1"># If the output is real-valued, we concatenate sin+cos of the features to</span>
            <span class="c1"># avoid ambiguities. Therefore, in this case the effective embed_dim is cut</span>
            <span class="c1"># in half. For the complex-valued case, we use complex numbers which each</span>
            <span class="c1"># represent sin+cos directly, so the ambiguity is avoided directly,</span>
            <span class="c1"># and this halving is not necessary.</span>
            <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>

<div class="viewcode-block" id="DiffusionStepEmbedding.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DiffusionStepEmbedding.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">fac</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span>
            <span class="mi">4</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">t</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">inner</span> <span class="o">=</span> <span class="n">t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">fac</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">inner</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">inner</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">inner</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ComplexLinear"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexLinear">[docs]</a><span class="k">class</span> <span class="nc">ComplexLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A potentially complex-valued linear layer. Reduces to a regular linear</span>
<span class="sd">    layer if `complex_valued=False`.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span> <span class="o">=</span> <span class="n">complex_valued</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">re</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">im</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>

<div class="viewcode-block" id="ComplexLinear.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexLinear.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">im</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FeatureMapDense"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.FeatureMapDense">[docs]</a><span class="k">class</span> <span class="nc">FeatureMapDense</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A fully connected layer that reshapes outputs to feature maps.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_valued</span> <span class="o">=</span> <span class="n">complex_valued</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">ComplexLinear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="n">complex_valued</span><span class="p">)</span>

<div class="viewcode-block" id="FeatureMapDense.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.FeatureMapDense.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="torch_complex_from_reim"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.torch_complex_from_reim">[docs]</a><span class="k">def</span> <span class="nf">torch_complex_from_reim</span><span class="p">(</span><span class="n">re</span><span class="p">,</span> <span class="n">im</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">re</span><span class="p">,</span> <span class="n">im</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span></div>


<div class="viewcode-block" id="ArgsComplexMultiplicationWrapper"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ArgsComplexMultiplicationWrapper">[docs]</a><span class="k">class</span> <span class="nc">ArgsComplexMultiplicationWrapper</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adapted from `asteroid`&#39;s `complex_nn.py`, allowing</span>
<span class="sd">        args/kwargs to be passed through forward().</span>

<span class="sd">    Make a complex-valued module `F` from a real-valued module `f` by applying</span>
<span class="sd">    complex multiplication rules:</span>

<span class="sd">    F(a + i b) = f1(a) - f1(b) + i (f2(b) + f2(a))</span>

<span class="sd">    where `f1`, `f2` are instances of `f` that do *not* share weights.</span>

<span class="sd">    Args:</span>
<span class="sd">        module_cls (callable): A class or function that returns a Torch</span>
<span class="sd">            module/functional. Constructor of `f` in the formula above.</span>
<span class="sd">            Called 2x with `*args`, `**kwargs`, to construct the real and imaginary</span>
<span class="sd">            component modules.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">re_module</span> <span class="o">=</span> <span class="n">module_cls</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">im_module</span> <span class="o">=</span> <span class="n">module_cls</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="ArgsComplexMultiplicationWrapper.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ArgsComplexMultiplicationWrapper.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch_complex_from_reim</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">re_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">im_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">re_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">im_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span>
        <span class="p">)</span></div></div>


<span class="n">ComplexConv2d</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">ArgsComplexMultiplicationWrapper</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span>
<span class="n">ComplexConvTranspose2d</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span>
    <span class="n">ArgsComplexMultiplicationWrapper</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span>
<span class="p">)</span>


<div class="viewcode-block" id="get_activation"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.get_activation">[docs]</a><span class="k">def</span> <span class="nf">get_activation</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;silu&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span>
    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span>
    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;leaky_relu&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown activation: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="BatchNorm"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.BatchNorm">[docs]</a><span class="k">class</span> <span class="nc">BatchNorm</span><span class="p">(</span><span class="n">_BatchNorm</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_check_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="nb">input</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;expected 4D or 3D input (got </span><span class="si">{}</span><span class="s2">D input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="OnReIm"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.OnReIm">[docs]</a><span class="k">class</span> <span class="nc">OnReIm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">re_module</span> <span class="o">=</span> <span class="n">module_cls</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">im_module</span> <span class="o">=</span> <span class="n">module_cls</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="OnReIm.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.OnReIm.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch_complex_from_reim</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">re_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">im_module</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">))</span></div></div>


<span class="c1"># Code for DCUNet largely copied from Danilo&#39;s `informedenh` repo, cheers!</span>


<div class="viewcode-block" id="unet_decoder_args"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.unet_decoder_args">[docs]</a><span class="k">def</span> <span class="nf">unet_decoder_args</span><span class="p">(</span><span class="n">encoders</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">skip_connections</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get list of decoder arguments for upsampling (right) side of a symmetric u-net,</span>
<span class="sd">    given the arguments used to construct the encoder.</span>
<span class="sd">    Args:</span>
<span class="sd">        encoders (tuple of length `N` of tuples of</span>
<span class="sd">            (in_chan, out_chan, kernel_size, stride, padding)):</span>
<span class="sd">            List of arguments used to construct the encoders</span>
<span class="sd">        skip_connections (bool): Whether to include skip connections in the</span>
<span class="sd">            calculation of decoder input channels.</span>
<span class="sd">    Return:</span>
<span class="sd">        tuple of length `N` of tuples of</span>
<span class="sd">            (in_chan, out_chan, kernel_size, stride, padding):</span>
<span class="sd">            Arguments to be used to construct decoders</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">decoder_args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="p">(</span>
        <span class="n">enc_in_chan</span><span class="p">,</span>
        <span class="n">enc_out_chan</span><span class="p">,</span>
        <span class="n">enc_kernel_size</span><span class="p">,</span>
        <span class="n">enc_stride</span><span class="p">,</span>
        <span class="n">enc_padding</span><span class="p">,</span>
        <span class="n">enc_dilation</span><span class="p">,</span>
    <span class="p">)</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">encoders</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">skip_connections</span> <span class="ow">and</span> <span class="n">decoder_args</span><span class="p">:</span>
            <span class="n">skip_in_chan</span> <span class="o">=</span> <span class="n">enc_out_chan</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">skip_in_chan</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">decoder_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">enc_out_chan</span> <span class="o">+</span> <span class="n">skip_in_chan</span><span class="p">,</span>
                <span class="n">enc_in_chan</span><span class="p">,</span>
                <span class="n">enc_kernel_size</span><span class="p">,</span>
                <span class="n">enc_stride</span><span class="p">,</span>
                <span class="n">enc_padding</span><span class="p">,</span>
                <span class="n">enc_dilation</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">decoder_args</span><span class="p">)</span></div>


<div class="viewcode-block" id="make_unet_encoder_decoder_args"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.make_unet_encoder_decoder_args">[docs]</a><span class="k">def</span> <span class="nf">make_unet_encoder_decoder_args</span><span class="p">(</span><span class="n">encoder_args</span><span class="p">,</span> <span class="n">decoder_args</span><span class="p">):</span>
    <span class="n">encoder_args</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">in_chan</span><span class="p">,</span>
            <span class="n">out_chan</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">),</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span>
            <span class="p">(</span>
                <span class="nb">tuple</span><span class="p">([</span><span class="n">n</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">kernel_size</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">padding</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span>
                <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">dilation</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">in_chan</span><span class="p">,</span> <span class="n">out_chan</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span> <span class="ow">in</span> <span class="n">encoder_args</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">decoder_args</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
        <span class="n">decoder_args</span> <span class="o">=</span> <span class="n">unet_decoder_args</span><span class="p">(</span>
            <span class="n">encoder_args</span><span class="p">,</span>
            <span class="n">skip_connections</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">decoder_args</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">in_ch</span><span class="p">,</span>
                <span class="n">out_ch</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">ks</span><span class="p">),</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span>
                <span class="nb">tuple</span><span class="p">([</span><span class="n">n</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">])</span> <span class="k">if</span> <span class="n">pad</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span> <span class="k">else</span> <span class="n">pad</span><span class="p">,</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="n">dilation</span><span class="p">),</span>
                <span class="n">out_pad</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">ks</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">out_pad</span> <span class="ow">in</span> <span class="n">decoder_args</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">encoder_args</span><span class="p">,</span> <span class="n">decoder_args</span></div>


<span class="n">DCUNET_ARCHITECTURES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;DCUNet-10&quot;</span><span class="p">:</span> <span class="n">make_unet_encoder_decoder_args</span><span class="p">(</span>
        <span class="c1"># Encoders:</span>
        <span class="c1"># (in_chan, out_chan, kernel_size, stride, padding, dilation)</span>
        <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">),</span>
        <span class="c1"># Decoders: automatic inverse</span>
        <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;DCUNet-16&quot;</span><span class="p">:</span> <span class="n">make_unet_encoder_decoder_args</span><span class="p">(</span>
        <span class="c1"># Encoders:</span>
        <span class="c1"># (in_chan, out_chan, kernel_size, stride, padding, dilation)</span>
        <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">),</span>
        <span class="c1"># Decoders: automatic inverse</span>
        <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;DCUNet-20&quot;</span><span class="p">:</span> <span class="n">make_unet_encoder_decoder_args</span><span class="p">(</span>
        <span class="c1"># Encoders:</span>
        <span class="c1"># (in_chan, out_chan, kernel_size, stride, padding, dilation)</span>
        <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">),</span>
        <span class="c1"># Decoders: automatic inverse</span>
        <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="s2">&quot;DilDCUNet-v2&quot;</span><span class="p">:</span> <span class="n">make_unet_encoder_decoder_args</span><span class="p">(</span>
        <span class="c1"># architecture used in SGMSE / Interspeech paper</span>
        <span class="c1"># Encoders:</span>
        <span class="c1"># (in_chan, out_chan, kernel_size, stride, padding, dilation)</span>
        <span class="p">(</span>
            <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">),</span>
        <span class="c1"># Decoders: automatic inverse</span>
        <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">}</span>


<div class="viewcode-block" id="DCUNet"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNet">[docs]</a><span class="k">class</span> <span class="nc">DCUNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dcunet_architecture</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;DilDCUNet-v2&quot;</span><span class="p">,</span>
        <span class="n">dcunet_time_embedding</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gfp&quot;</span><span class="p">,</span>
        <span class="n">dcunet_temb_layers_global</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">dcunet_temb_layers_local</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">dcunet_temb_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;silu&quot;</span><span class="p">,</span>
        <span class="n">dcunet_time_embedding_complex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dcunet_fix_length</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;pad&quot;</span><span class="p">,</span>
        <span class="n">dcunet_mask_bound</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">dcunet_norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;bN&quot;</span><span class="p">,</span>
        <span class="n">dcunet_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;relu&quot;</span><span class="p">,</span>
        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="n">dcunet_architecture</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fix_length_mode</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">dcunet_fix_length</span> <span class="k">if</span> <span class="n">dcunet_fix_length</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">=</span> <span class="n">dcunet_norm_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">dcunet_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="c1"># for x_t and y -- note that this is 2 rather than 4,</span>
        <span class="c1"># because we directly treat complex channels in this DNN</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">dcunet_time_embedding</span> <span class="k">if</span> <span class="n">dcunet_time_embedding</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding_complex</span> <span class="o">=</span> <span class="n">dcunet_time_embedding_complex</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers_global</span> <span class="o">=</span> <span class="n">dcunet_temb_layers_global</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers_local</span> <span class="o">=</span> <span class="n">dcunet_temb_layers_local</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span> <span class="o">=</span> <span class="n">dcunet_temb_activation</span>
        <span class="n">conf_encoders</span><span class="p">,</span> <span class="n">conf_decoders</span> <span class="o">=</span> <span class="n">DCUNET_ARCHITECTURES</span><span class="p">[</span><span class="n">dcunet_architecture</span><span class="p">]</span>

        <span class="c1"># Replace `input_channels` in encoders config</span>
        <span class="n">_replaced_input_channels</span><span class="p">,</span> <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">conf_encoders</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">encoders</span> <span class="o">=</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">,</span> <span class="o">*</span><span class="n">rest</span><span class="p">),</span> <span class="o">*</span><span class="n">conf_encoders</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">decoders</span> <span class="o">=</span> <span class="n">conf_decoders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoders_stride_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
            <span class="p">[</span><span class="n">enc_stride</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">enc_stride</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">encoders</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>

        <span class="c1"># Prepare kwargs for encoder and decoder</span>
        <span class="c1"># (to potentially be modified before layer instantiation)</span>
        <span class="n">encoder_decoder_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">norm_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">temb_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_layers_local</span><span class="p">,</span>
            <span class="n">temb_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Instantiate (global) time embedding layer</span>
        <span class="n">embed_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">complex_valued</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding_complex</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="o">==</span> <span class="s2">&quot;gfp&quot;</span><span class="p">:</span>
                <span class="n">embed_ops</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="n">GaussianFourierProjection</span><span class="p">(</span>
                        <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="n">complex_valued</span>
                    <span class="p">)</span>
                <span class="p">]</span>
                <span class="n">encoder_decoder_kwargs</span><span class="p">[</span><span class="s2">&quot;embed_dim&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_dim</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="o">==</span> <span class="s2">&quot;ds&quot;</span><span class="p">:</span>
                <span class="n">embed_ops</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="n">DiffusionStepEmbedding</span><span class="p">(</span>
                        <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="n">complex_valued</span>
                    <span class="p">)</span>
                <span class="p">]</span>
                <span class="n">encoder_decoder_kwargs</span><span class="p">[</span><span class="s2">&quot;embed_dim&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">embed_dim</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding_complex</span><span class="p">:</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="ow">in</span> <span class="p">(</span>
                    <span class="s2">&quot;gfp&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;ds&quot;</span><span class="p">,</span>
                <span class="p">),</span> <span class="s2">&quot;Complex timestep embedding only available for gfp and ds&quot;</span>
                <span class="n">encoder_decoder_kwargs</span><span class="p">[</span><span class="s2">&quot;complex_time_embedding&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_layers_global</span><span class="p">):</span>
                <span class="n">embed_ops</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="n">ComplexLinear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="n">dcunet_temb_activation</span><span class="p">)),</span>
                <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">embed_ops</span><span class="p">)</span>

        <span class="c1"># Instantiate DCUNet layers #</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">ComplexConvTranspose2d</span><span class="p">(</span><span class="o">*</span><span class="n">decoders</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">encoders</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DCUNetComplexEncoderBlock</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_decoder_kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">args</span> <span class="ow">in</span> <span class="n">encoders</span>
        <span class="p">]</span>
        <span class="n">decoders</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">DCUNetComplexDecoderBlock</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_decoder_kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">args</span> <span class="ow">in</span> <span class="n">decoders</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mask_bound</span> <span class="o">=</span> <span class="n">dcunet_mask_bound</span> <span class="k">if</span> <span class="n">dcunet_mask_bound</span> <span class="o">!=</span> <span class="s2">&quot;none&quot;</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_bound</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;sorry, mask bounding not implemented at the moment&quot;</span>
            <span class="p">)</span>
            <span class="c1"># TODO we can&#39;t use nn.Sequential since the ComplexConvTranspose2d needs a</span>
            <span class="c1"># second `output_size` argument</span>
        <span class="c1"># operations = (output_layer, complex_nn.BoundComplexMask(self.mask_bound))</span>
        <span class="c1"># output_layer = nn.Sequential(*[x for x in operations if x is not None])</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoders</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoders</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">encoders</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">decoders</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">output_layer</span> <span class="ow">or</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

<div class="viewcode-block" id="DCUNet.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNet.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Input shape is expected to be $(batch, nfreqs, time)$, with $nfreqs - 1$</span>
<span class="sd">        divisible by $f_0 * f_1 * ... * f_N$ where $f_k$ are the frequency strides</span>
<span class="sd">        of the encoders, and $time - 1$ is divisible by $t_0 * t_1 * ... * t_N$</span>
<span class="sd">        where $t_N$ are the time strides of the encoders.</span>
<span class="sd">        Args:</span>
<span class="sd">            spec (Tensor): complex spectrogram tensor. 1D, 2D or 3D tensor, time last.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor, of shape (batch, time) or (time).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TF-rep shape: (batch, self.input_channels, n_fft, frames)</span>
        <span class="c1"># Estimate mask from time-frequency representation.</span>
        <span class="n">x_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fix_input_dims</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_in</span>
        <span class="n">t_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">0</span><span class="n">j</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_embedding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">enc_outs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">enc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">enc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t_embed</span><span class="p">)</span>
            <span class="c1"># UNet skip connection</span>
            <span class="n">enc_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">enc_out</span><span class="p">,</span> <span class="n">dec</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">enc_outs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoders</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t_embed</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">enc_out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">x_in</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># output shape: (batch, 1, n_fft, frames)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fix_output_dims</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="DCUNet.fix_input_dims"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNet.fix_input_dims">[docs]</a>    <span class="k">def</span> <span class="nf">fix_input_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_fix_dcu_input_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fix_length_mode</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders_stride_product</span><span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DCUNet.fix_output_dims"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNet.fix_output_dims">[docs]</a>    <span class="k">def</span> <span class="nf">fix_output_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_fix_dcu_output_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fix_length_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_fix_dcu_input_dims</span><span class="p">(</span><span class="n">fix_length_mode</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">encoders_stride_product</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pad or trim `x` to a length compatible with DCUNet.&quot;&quot;&quot;</span>
    <span class="n">freq_prod</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">encoders_stride_product</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">time_prod</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">encoders_stride_product</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">freq_prod</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Input shape must be [batch, ch, freq + 1, time + 1] &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;with freq divisible by &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">freq_prod</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> instead&quot;</span>
        <span class="p">)</span>
    <span class="n">time_remainder</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">time_prod</span>
    <span class="k">if</span> <span class="n">time_remainder</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">fix_length_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Input shape must be [batch, ch, freq + 1, time + 1] with time &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;divisible by </span><span class="si">{</span><span class="n">time_prod</span><span class="si">}</span><span class="s2">, got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; Set the &#39;fix_length_mode&#39; argument &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;in &#39;DCUNet&#39; to &#39;pad&#39; or &#39;trim&#39; to fix shapes automatically.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">fix_length_mode</span> <span class="o">==</span> <span class="s2">&quot;pad&quot;</span><span class="p">:</span>
            <span class="n">pad_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">time_prod</span> <span class="o">-</span> <span class="n">time_remainder</span><span class="p">]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pad_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">fix_length_mode</span> <span class="o">==</span> <span class="s2">&quot;trim&quot;</span><span class="p">:</span>
            <span class="n">pad_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">time_remainder</span><span class="p">]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pad_shape</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown fix_length mode &#39;</span><span class="si">{</span><span class="n">fix_length_mode</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">_fix_dcu_output_dims</span><span class="p">(</span><span class="n">fix_length_mode</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fix shape of `out` to the original shape of `x` by padding/cropping.&quot;&quot;&quot;</span>
    <span class="n">inp_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">output_len</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">inp_len</span> <span class="o">-</span> <span class="n">output_len</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_get_norm</span><span class="p">(</span><span class="n">norm_type</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;CbN&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ComplexBatchNorm</span>
    <span class="k">elif</span> <span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;bN&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">partial</span><span class="p">(</span><span class="n">OnReIm</span><span class="p">,</span> <span class="n">BatchNorm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown norm type: </span><span class="si">{</span><span class="n">norm_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="DCUNetComplexEncoderBlock"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNetComplexEncoderBlock">[docs]</a><span class="k">class</span> <span class="nc">DCUNetComplexEncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_chan</span><span class="p">,</span>
        <span class="n">out_chan</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">,</span>
        <span class="n">norm_type</span><span class="o">=</span><span class="s2">&quot;bN&quot;</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
        <span class="n">embed_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">complex_time_embedding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">temb_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">temb_activation</span><span class="o">=</span><span class="s2">&quot;silu&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_chan</span> <span class="o">=</span> <span class="n">in_chan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_chan</span> <span class="o">=</span> <span class="n">out_chan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers</span> <span class="o">=</span> <span class="n">temb_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span> <span class="o">=</span> <span class="n">temb_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_time_embedding</span> <span class="o">=</span> <span class="n">complex_time_embedding</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">ComplexConv2d</span><span class="p">(</span>
            <span class="n">in_chan</span><span class="p">,</span>
            <span class="n">out_chan</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="n">norm_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">_get_norm</span><span class="p">(</span><span class="n">norm_type</span><span class="p">)(</span><span class="n">out_chan</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="n">activation</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ops</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
                <span class="n">ops</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="n">ComplexLinear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span><span class="p">)),</span>
                <span class="p">]</span>
            <span class="n">ops</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">FeatureMapDense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_chan</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span><span class="p">)),</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embed_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">ops</span><span class="p">)</span>

<div class="viewcode-block" id="DCUNetComplexEncoderBlock.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNetComplexEncoderBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t_embed</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_layer</span><span class="p">(</span><span class="n">t_embed</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="DCUNetComplexDecoderBlock"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNetComplexDecoderBlock">[docs]</a><span class="k">class</span> <span class="nc">DCUNetComplexDecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_chan</span><span class="p">,</span>
        <span class="n">out_chan</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">,</span>
        <span class="n">output_padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="n">norm_type</span><span class="o">=</span><span class="s2">&quot;bN&quot;</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
        <span class="n">embed_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">temb_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">temb_activation</span><span class="o">=</span><span class="s2">&quot;swish&quot;</span><span class="p">,</span>
        <span class="n">complex_time_embedding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_chan</span> <span class="o">=</span> <span class="n">in_chan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_chan</span> <span class="o">=</span> <span class="n">out_chan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_padding</span> <span class="o">=</span> <span class="n">output_padding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">complex_time_embedding</span> <span class="o">=</span> <span class="n">complex_time_embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers</span> <span class="o">=</span> <span class="n">temb_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span> <span class="o">=</span> <span class="n">temb_activation</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">deconv</span> <span class="o">=</span> <span class="n">ComplexConvTranspose2d</span><span class="p">(</span>
            <span class="n">in_chan</span><span class="p">,</span>
            <span class="n">out_chan</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="p">,</span>
            <span class="n">output_padding</span><span class="p">,</span>
            <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="n">norm_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">_get_norm</span><span class="p">(</span><span class="n">norm_type</span><span class="p">)(</span><span class="n">out_chan</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="n">activation</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ops</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">temb_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)):</span>
                <span class="n">ops</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="n">ComplexLinear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span><span class="p">)),</span>
                <span class="p">]</span>
            <span class="n">ops</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">FeatureMapDense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_chan</span><span class="p">,</span> <span class="n">complex_valued</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">OnReIm</span><span class="p">(</span><span class="n">get_activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">temb_activation</span><span class="p">)),</span>
            <span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">embed_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">ops</span><span class="p">)</span>

<div class="viewcode-block" id="DCUNetComplexDecoderBlock.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.DCUNetComplexDecoderBlock.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t_embed</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deconv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">output_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_layer</span><span class="p">(</span><span class="n">t_embed</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">y</span><span class="p">))</span></div></div>


<span class="c1"># From https://github.com/chanil1218/DCUnet.pytorch/blob/</span>
<span class="c1"># 2dcdd30804be47a866fde6435cbb7e2f81585213/models/layers/complexnn.py</span>
<div class="viewcode-block" id="ComplexBatchNorm"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexBatchNorm">[docs]</a><span class="k">class</span> <span class="nc">ComplexBatchNorm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_features</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ComplexBatchNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">affine</span> <span class="o">=</span> <span class="n">affine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span> <span class="o">=</span> <span class="n">track_running_stats</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wrr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wri</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wii</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Br</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Bi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;Wrr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;Wri&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;Wii&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;Br&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;Bi&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;RMr&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;RMi&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;RVrr&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;RVri&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;RVii&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="s2">&quot;num_batches_tracked&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;RMr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;RMi&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;RVrr&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;RVri&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;RVii&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s2">&quot;num_batches_tracked&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

<div class="viewcode-block" id="ComplexBatchNorm.reset_running_stats"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexBatchNorm.reset_running_stats">[docs]</a>    <span class="k">def</span> <span class="nf">reset_running_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">RMr</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">RMi</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">RVrr</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">RVri</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">RVii</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span></div>

<div class="viewcode-block" id="ComplexBatchNorm.reset_parameters"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexBatchNorm.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_running_stats</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Br</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Bi</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wrr</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wri</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.9</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.9</span><span class="p">)</span>  <span class="c1"># W will be positive-definite</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Wii</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_check_input_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xr</span><span class="p">,</span> <span class="n">xi</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">xr</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">xi</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">xr</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span>

<div class="viewcode-block" id="ComplexBatchNorm.forward"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexBatchNorm.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">xr</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">imag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_input_dim</span><span class="p">(</span><span class="n">xr</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>

        <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># use cumulative moving average</span>
                <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_batches_tracked</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># use exponential moving average</span>
                <span class="n">exponential_average_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>

        <span class="c1">#</span>
        <span class="c1"># NOTE: The precise meaning of the &quot;training flag&quot; is:</span>
        <span class="c1">#       True:  Normalize using batch   statistics, update running statistics</span>
        <span class="c1">#              if they are being collected.</span>
        <span class="c1">#       False: Normalize using running statistics, ignore batch   statistics.</span>
        <span class="c1">#</span>
        <span class="n">training</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span>
        <span class="n">redux</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">xr</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">vdim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">xr</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="n">vdim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">xr</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1">#</span>
        <span class="c1"># Mean M Computation and Centering</span>
        <span class="c1">#</span>
        <span class="c1"># Includes running mean update if training and running.</span>
        <span class="c1">#</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">Mr</span><span class="p">,</span> <span class="n">Mi</span> <span class="o">=</span> <span class="n">xr</span><span class="p">,</span> <span class="n">xi</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">redux</span><span class="p">:</span>
                <span class="n">Mr</span> <span class="o">=</span> <span class="n">Mr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">Mi</span> <span class="o">=</span> <span class="n">Mi</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">RMr</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">Mr</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">exponential_average_factor</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">RMi</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">Mi</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">exponential_average_factor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Mr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RMr</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
            <span class="n">Mi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RMi</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
        <span class="n">xr</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">xr</span> <span class="o">-</span> <span class="n">Mr</span><span class="p">,</span> <span class="n">xi</span> <span class="o">-</span> <span class="n">Mi</span>

        <span class="c1">#</span>
        <span class="c1"># Variance Matrix V Computation</span>
        <span class="c1">#</span>
        <span class="c1"># Includes epsilon numerical stabilizer/Tikhonov regularizer.</span>
        <span class="c1"># Includes running variance update if training and running.</span>
        <span class="c1">#</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">Vrr</span> <span class="o">=</span> <span class="n">xr</span> <span class="o">*</span> <span class="n">xr</span>
            <span class="n">Vri</span> <span class="o">=</span> <span class="n">xr</span> <span class="o">*</span> <span class="n">xi</span>
            <span class="n">Vii</span> <span class="o">=</span> <span class="n">xi</span> <span class="o">*</span> <span class="n">xi</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">redux</span><span class="p">:</span>
                <span class="n">Vrr</span> <span class="o">=</span> <span class="n">Vrr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">Vri</span> <span class="o">=</span> <span class="n">Vri</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">Vii</span> <span class="o">=</span> <span class="n">Vii</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">RVrr</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">Vrr</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">exponential_average_factor</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">RVri</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">Vri</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">exponential_average_factor</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">RVii</span><span class="o">.</span><span class="n">lerp_</span><span class="p">(</span><span class="n">Vii</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">exponential_average_factor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Vrr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RVrr</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
            <span class="n">Vri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RVri</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
            <span class="n">Vii</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">RVii</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
        <span class="n">Vrr</span> <span class="o">=</span> <span class="n">Vrr</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>
        <span class="n">Vri</span> <span class="o">=</span> <span class="n">Vri</span>
        <span class="n">Vii</span> <span class="o">=</span> <span class="n">Vii</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span>

        <span class="c1">#</span>
        <span class="c1"># Matrix Inverse Square Root U = V^-0.5</span>
        <span class="c1">#</span>
        <span class="c1"># sqrt of a 2x2 matrix,</span>
        <span class="c1"># - https://en.wikipedia.org/wiki/Square_root_of_a_2_by_2_matrix</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">Vrr</span> <span class="o">+</span> <span class="n">Vii</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">Vrr</span> <span class="o">*</span> <span class="n">Vii</span><span class="p">,</span> <span class="n">Vri</span><span class="p">,</span> <span class="n">Vri</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">delta</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="p">(</span><span class="n">tau</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

        <span class="c1"># matrix inverse, http://mathworld.wolfram.com/MatrixInverse.html</span>
        <span class="n">rst</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">()</span>
        <span class="n">Urr</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="n">Vii</span><span class="p">)</span> <span class="o">*</span> <span class="n">rst</span>
        <span class="n">Uii</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">+</span> <span class="n">Vrr</span><span class="p">)</span> <span class="o">*</span> <span class="n">rst</span>
        <span class="n">Uri</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">Vri</span><span class="p">)</span> <span class="o">*</span> <span class="n">rst</span>

        <span class="c1">#</span>
        <span class="c1"># Optionally left-multiply U by affine weights W to produce combined</span>
        <span class="c1"># weights Z, left-multiply the inputs by Z, then optionally bias them.</span>
        <span class="c1">#</span>
        <span class="c1"># y = Zx + B</span>
        <span class="c1"># y = WUx + B</span>
        <span class="c1"># y = [Wrr Wri][Urr Uri] [xr] + [Br]</span>
        <span class="c1">#     [Wir Wii][Uir Uii] [xi]   [Bi]</span>
        <span class="c1">#</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="n">Wrr</span><span class="p">,</span> <span class="n">Wri</span><span class="p">,</span> <span class="n">Wii</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Wrr</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Wri</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Wii</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">Zrr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Wrr</span> <span class="o">*</span> <span class="n">Urr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Wri</span> <span class="o">*</span> <span class="n">Uri</span><span class="p">)</span>
            <span class="n">Zri</span> <span class="o">=</span> <span class="p">(</span><span class="n">Wrr</span> <span class="o">*</span> <span class="n">Uri</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Wri</span> <span class="o">*</span> <span class="n">Uii</span><span class="p">)</span>
            <span class="n">Zir</span> <span class="o">=</span> <span class="p">(</span><span class="n">Wri</span> <span class="o">*</span> <span class="n">Urr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Wii</span> <span class="o">*</span> <span class="n">Uri</span><span class="p">)</span>
            <span class="n">Zii</span> <span class="o">=</span> <span class="p">(</span><span class="n">Wri</span> <span class="o">*</span> <span class="n">Uri</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Wii</span> <span class="o">*</span> <span class="n">Uii</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Zrr</span><span class="p">,</span> <span class="n">Zri</span><span class="p">,</span> <span class="n">Zir</span><span class="p">,</span> <span class="n">Zii</span> <span class="o">=</span> <span class="n">Urr</span><span class="p">,</span> <span class="n">Uri</span><span class="p">,</span> <span class="n">Uri</span><span class="p">,</span> <span class="n">Uii</span>

        <span class="n">yr</span> <span class="o">=</span> <span class="p">(</span><span class="n">Zrr</span> <span class="o">*</span> <span class="n">xr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Zri</span> <span class="o">*</span> <span class="n">xi</span><span class="p">)</span>
        <span class="n">yi</span> <span class="o">=</span> <span class="p">(</span><span class="n">Zir</span> <span class="o">*</span> <span class="n">xr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">Zii</span> <span class="o">*</span> <span class="n">xi</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">affine</span><span class="p">:</span>
            <span class="n">yr</span> <span class="o">=</span> <span class="n">yr</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Br</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>
            <span class="n">yi</span> <span class="o">=</span> <span class="n">yi</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">Bi</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">vdim</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">yr</span><span class="p">,</span> <span class="n">yi</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span></div>

<div class="viewcode-block" id="ComplexBatchNorm.extra_repr"><a class="viewcode-back" href="../../../../_gen/espnet2.enh.html#espnet2.enh.layers.dcunet.ComplexBatchNorm.extra_repr">[docs]</a>    <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="s2">&quot;</span><span class="si">{num_features}</span><span class="s2">, eps=</span><span class="si">{eps}</span><span class="s2">, momentum=</span><span class="si">{momentum}</span><span class="s2">, affine=</span><span class="si">{affine}</span><span class="s2">, &quot;</span>
            <span class="s2">&quot;track_running_stats=</span><span class="si">{track_running_stats}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="p">)</span></div></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">DCUNet</span><span class="p">()</span>
    <span class="n">dnn_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">257</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">257</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">dnn_input</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>